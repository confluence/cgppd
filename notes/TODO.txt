--------------------------------------------------------------------------------
NOW
--------------------------------------------------------------------------------

* move various weird parameter-overriding things to the same place

* put checkpointing back in
    * save individual pdb files
    * save checkpointing file with list of pdb files to load and iteration count
    * when resuming, make sure the iteration count is increased and e.g. sampling starts immediately if it needs to
    * save/load:
        * parameters.currentStep

* start writing up
    * skeleton
    * design / implementation of changes chapter

* make sure all the non-crowders are actually loaded before all the crowders (don't rely on the input file to be correct)
* single rng for all replicas
* clean up CUDA a bit more (setting up and tearing down)
* clean up the file stuff

* figure out how run / the threadable function actually work

* extend unit test to a reasonably complete normal simulation (with reading of parameters, etc.)
* mock rng (?) for a predictable set of steps?

--------------------------------------------------------------------------------
THEN
--------------------------------------------------------------------------------

* postprocess: write it completely separately in Python

* make flex and crankshaft moves optional

* Linkers, etc. don't actually *need* to be arrays. Just keep them as vectors.
* is it really necessary to use custom vector3f and vector3d types?
* is it really necessary to use size_t for iterators instead of int?

* Reorder methods and attributes, especially in header.  SETUP, MC MOVES, POTENTIAL CALCULATION

* MOLECULE: constructor / destructor
    * reserveResidueSpace not consistently used?
    * maybe use init from pdb function with rotation / translation params?
    * make Molecule::rotate call Molecule::setRotation, etc.?
* AMINO ACIDS
    * clean up read from file

MAKEFILE
* Use config for compilation options?
* Print out whether compiled with flexible linkers

--------------------------------------------------------------------------------
SOON
--------------------------------------------------------------------------------

WRITE
* Thesis skeleton
* Background chapter
    * Visualisation: graphs of LJ and DH potential vs residue distance (? -- for different types)
* Implementation

ADD
* Extra MC moves (just domain rotation?) on GPU?
* Make angle terms, crankshaft moves optional; test efficiency / accuracy of including them
* Make flexing optional; doesn't really work in cases with flexible loops coming out of domains.
* Validation with a simple test case
* Is the caching stuff actually a good idea, or is it just overhead?
    * Write another version of the CPU bond calculation, which throws out the caching and calculates everything
* What happens if molecule consists of multiple chains?

TEST
Potential:
* test data
* !!! check performance of CPU NC E with doubles / floats
* unit test for kahan sums, repulsive crowding

TEST
* write an end-to-end test for optimisation comparisons
    * is component-wise addition of vectors important?
    * is caching of internal potential subtotals important?

--------------------------------------------------------------------------------
LATER
--------------------------------------------------------------------------------

* Nice examples to go in paper

--------------------------------------------------------------------------------
EVENTUALLY
--------------------------------------------------------------------------------

OPTIMISE

* is it *actually* worth summing vector components separately?

* init of gpu memory seems slower (underlying software change?)

* Now that there's more time, try doing stuff on GPU:
    * one molecule only (since only one molecule will have internal changes?)
    * but then we have to cache at the molecule level at least, so that potential comparison works
    * LJ/DH seems like a really good idea
    * single kernel based on segments, or aditional kernel just for internal segments?
    * Friedrichs, et al.have a kernel for bonded forces

ADD
* Multiple GPUs?  Does that work?
